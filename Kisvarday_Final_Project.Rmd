
---
title: "BMI 715 Final Project: *** "
author: "Susannah Kisvarday"
output:
  html_document: 
    toc: true
    toc_depth: 3
    toc_float: true
  html_notebook: default
  pdf_document: default
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T)
library(tidyverse)
library(dplyr)
library(MASS)
library(caret)
library(Metrics)
```

# Importing the data

```{r}
nhanes_raw <- read.csv("C:/BMI Masters/Fall2022/BMI715/FinalProject/nhanes_13_14_subset.csv")

#Seeing how many observations and variables I have to work with:

dim(nhanes_raw)

# I added the rest of the code in this r chunk after Luke put out the updated dataset:
nhanes_raw2 <- read.csv("C:/BMI Masters/Fall2022/BMI715/FinalProject/nhanes_13_14_subset_updated.csv")

dim(nhanes_raw2)

#looks like it is the same number of observations, but almost 100 new columns were added--that's a lot.  The ones that I might find interesting are RIAGENDR (gender), BMXBMI (BMI), DIQ172 ("Do you feel you could be at risk for developing diabetes?"), and SMQ020 ("smoked at least 100 cigarettes in life").  These seem compelling enough that I think it will be worth it for me to update my code to use the new data set.

  
```


## Exploring the data

I scrolled through the Excel file and there seem to be quite a lot of NAs.  10,175 rows of data seems like a good amount of observations, but some columns seem to be mostly NA.  Just to better understand what data I actually have, I wanted to see how many observations were available for each variable.

```{r, eval=TRUE}

nhanes_obs_count <- as.data.frame(apply(!is.na(nhanes_raw2), 2, sum))

#  renaming that unfortunate column name :`apply(!is.na(nhanes_raw), 2, sum)`

nhanes_obsCount <- nhanes_obs_count %>% rename(ObsCount = `apply(!is.na(nhanes_raw2), 2, sum)`)

#calling the dataframe, so that I can see which variables have more information to work with:
nhanes_obsCount

```

I noticed that there are a lot of columns that have very few observations (for instance one column had only 2 data points).  Some of the new smoking questions actually have no non-NA values at all!  


Getting and idea of what variables have data (rather than NA) for more than half of the observations.  

```{r, eval=TRUE}

sum(nhanes_obsCount$ObsCount > 5000)
nhn_5000 <- nhanes_obsCount %>% filter(nhanes_obsCount$ObsCount > 5000)
nhn_5000


```

This is good...some of the smoking quesitons have quite a lot of data (some even have >10000 observations).  My new SMQ020 has 6113 observations which is similar to the numbers of the other variables that I was already working with.


Getting a deeper look at some of the variables such as counts for children with asthma, how many people have psoriasis, and hemoglobin A1c range.

```{r}

#Graph of the age variable to get an idea of the pediatric observations available:

hist(nhanes_raw2$RIDAGEYR)
ped <- nhanes_raw2 %>% filter(RIDAGEYR < 25)
hist(ped$RIDAGEYR)
hist(ped$MCQ010)
nrow(ped)

#checking for pediatric asthma in particular:
ped_asthma <- ped %>% filter(MCQ010 == 1)
nrow(ped_asthma)

#psoriasis is intriguing because we don't have a clear understanding of the risk factors for psoriasis:
psor <- nhanes_raw2 %>% filter(MCQ070 == 1)
nrow(psor)
#however after looking more carefully at the rest of the variables available, I don't think there are enough available variables that could potentially be related to psoriasis, so:


#How about looking at risk factors for diabetes?  A1c would be a good marker of diabetes IF we have an adequate range of A1c values.
nhn_GH_noNA <- nhanes_raw2 %>% filter(!is.na(LBXGH))
nrow(nhn_GH_noNA)

min(nhn_GH_noNA$LBXGH)
max(nhn_GH_noNA$LBXGH)

#Looks like we have a really range of A1c values, and there are many potential risk factor variables included in this data set. Also, I found a very nice article related to trying to determine diabetes risk factors.  I think we have a winner!  


```

I'm thinking about removing rows where LBXGH = NA:  I looked through the rows wherein LBXGH was NA, and the rows where LBXGH=NA also have NAs in almost all other variables that I think may be risk factors for diabetes.  Removing the rows where LBXGH is NA removes very little other data, and I see no pattern as to what data is present in the rows where LBXGH is NA.  I don't think I would be introducing bias by removing these rows. 


I'm thinking about building a model (for risk factor prediction) with A1c as the dependent variable.  So I need to look closer at the normality assumption for modeling the LBXGH data: 

```{r, eval=TRUE}


hist(nhn_GH_noNA$LBXGH)

# A1c has a clear right-skew.  Log transformation will help this data become more like a normal distribution.

DM_log <- log(nhn_GH_noNA$LBXGH)
hist(DM_log)

#The log data still have a right skew, but I have clear improvement.

DM_sqrt <- sqrt(nhn_GH_noNA$LBXGH)
hist(DM_sqrt)

DM_cubeRoot <- (nhn_GH_noNA$LBXGH)^(1/3)
hist(DM_cubeRoot)

#Square root and cube root look less normal than log.

#Trying to estimate whether any of these transformed data vectors would pass the normality assumption by doing a Shapiro-Wilk test on samples from the data vectors (The R help section tells me that for shapiro.test, sample size must be between 3 and 5000, so I am going to just look at a random sample of my data).

#pull a random sample from each data vector (I modified this code from the code that Luke provided for splitting the data into train-test sets.)
set.seed(715)

sample_A1c <- createDataPartition(y = nhn_GH_noNA$LBXGH, p = 0.6, list = FALSE)
nrow(sample_A1c)
sample_log <- createDataPartition(y = DM_log, p = 0.6, list = FALSE)
sample_sqrt <- createDataPartition(y = DM_sqrt, p = 0.6, list = FALSE)
sample_cubeRoot <- createDataPartition(y = DM_cubeRoot, p = 0.6, list = FALSE)

#Run Shapiro-Wilk test:

shapiro.test(sample_A1c)
shapiro.test(sample_log)
shapiro.test(sample_sqrt)
shapiro.test(sample_cubeRoot)

```

What all of this tells me is that my A1c data is not normally distributed.  Taking the log of A1c makes it appear more normal, but it is still not normally distributed.  Square root and cube root are not as good as log.  None of these are normal.  But I talked to one of the TAs, and she says it is okay to just move forward using the log LBXGH data.  
Leaning into my domain knowledge ;) I realize that in terms of predicting diabetes (or even uncontrolled diabetes), it would not matter if the A1c were 17.1 or 10.1-both are extremely high indicators of uncontrolled diabetes.  I could transform the A1c data to bring high A1c results back closer to the mean in a way that would still retain the meaning, but that is outside the scale/scope of this class project.  



# Looking closer at the diabetes data's relationship to some of the other variables: 

```{r, eval=TRUE}

plot(nhn_GH_noNA$RIDAGEYR, nhn_GH_noNA$LBXGH)
plot(nhn_GH_noNA$RIDAGEYR, DM_log)
plot(nhn_GH_noNA$LBXSATSI, DM_log)
plot(nhn_GH_noNA$LBXSUA, DM_log)
plot(nhn_GH_noNA$BPQ020, nhn_GH_noNA$LBXGH)
plot(nhn_GH_noNA$BPQ020, DM_log)
plot(nhn_GH_noNA$BPXSY1, DM_log)
plot(nhn_GH_noNA$BPXSY1, nhn_GH_noNA$LBXGH)

#For fun, let's add my new gender and smoking variables:  Also, a couple of outliers messed up my ALT graph.  I will graph it again after I have removed the outliers from the dataset.  

plot(nhn_GH_noNA$RIAGENDR, DM_log)
plot(nhn_GH_noNA$SMQ020, DM_log)

#I should have realized these were binomial variables (categorical actually, but either way, the graphs don't look like much).

plot(nhn_GH_noNA$BMXBMI, DM_log)
plot(nhn_GH_noNA$BMXBMI, nhn_GH_noNA$LBXGH)

```

Age seems to be a somewhat linear relationship between LogA1c (and A1c).  UA may be linear as well (with the density of data points, it is difficult to tell.)  As systolic blood pressure and BMI rise, A1c level rises; but this does not appear to be a truly linear relationship.  


## Paper on Diabetes Risk Factors

I have decided to move forward with trying to create a diabetes predictive model.  I found an interesting paper that outlines quite a few diabetes risk factors-many of which are in our nhanes data set.  

```{txt}

#Here is a URL link to the paper that is the inspiration for this project.  

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860745/pdf/pone.0194127.pdf


```

To be clear, HgbA1c is a marker of diabetes, and diabetes disease definition is HgbA1c > 6.5.  I am not creating a model for whether a person has diabetes or not; my model will be predicting HgbA1c level based on the variables identified in the above paper and other variables that were available in our dataset.
And more even more specifically, I will build my model using the log of A1c level for the reason discussed above.



# Creating the data frame with variables of interest.

Making a data frame with just the variables of potential interest 

```{r, eval=TRUE}

#Data frame updated with new variables after Luke released more.

head(nhanes_raw2)
nhn_DM <- nhanes_raw2 %>% dplyr::select(LBXGH, LBXSUA, LBXSGTSI, LBXSATSI, LBXSCH, RIDAGEYR, RIAGENDR, IND235, MCQ080, MCQ300C, PAQ710, PAQ715, PAQ655, PAQ706, SLQ050, SLQ060, BPQ020, BPXSY1, MCQ365A, SMQ020, DIQ172, BMXBMI) 

head(nhn_DM)
str(nhn_DM)


```



# Examining these variables a little more closely:

I have some survey data that is binomial (MCQ080, MCQ300C, SLQ050, SLQ060, BPQ020, and MCQ365A).  I also have a couple of categorical variables (described in more detail below).  The rest is continuous numerical/integer data.  Total cholesterol and systolic blood pressure are 3 digit numbers (as are some of the GGT and ALT readings.  The rest of the numeric data is 1 or two digit.


```{r}
#And now RIAGENDR, DIQ172 and SMQ020 are binomial as well.

nhn_SCH_noNA <- nhanes_raw %>% filter(!is.na(LBXSCH))
min(nhn_SCH_noNA$LBXSCH)
max(nhn_SCH_noNA$LBXSCH)
hist(nhn_SCH_noNA$LBXSCH)

#Side note:  too bad I didn't choose to look at cholesterol--it looks pretty normally distributed.

```


I have decided that the numeric values are in a close enough range that they do not need to be scaled; this is fortunate for me because having non-scaled data will allow me to discuss a value's units when analyzing the data.  
That having been said, while looking at this data, I saw that the max cholesterol was 639 which sounds clinically unbelievable.  I went back to the Excel sheet, and it looks like this is a single outlier which may have been entered in error (vs rare disease).  I will need to make sure to clean the data for outliers like this in all of my variable categories later.  


Checking to see how many observations I have for each variable:

```{r}

nhn_DM_obsCount <- apply(!is.na(nhn_DM), 2, sum)
nhn_DM_obsCount


```


# Removing rows wherein my dependent variable (LBXGH) is NA


```{r}

nhn_GH_noNA <- nhn_DM %>% filter(!is.na(LBXGH))
head(nhn_GH_noNA)
dim(nhn_GH_noNA)

```

Okay, how many observations do I have for each variable now that I am only looking at the rows for which A1c was not NA?

```{r}


nhn_DM_obsCount2 <- apply(!is.na(nhn_GH_noNA), 2, sum)
nhn_DM_obsCount2

#Just to make it easy to look at how many NAs are in each column, I will look at this vector as well"

nhn_DM_NACount <- apply(is.na(nhn_GH_noNA), 2, sum)
nhn_DM_NACount

#I will likely need to get rid of categories that have more NAs--get rid of PAQ655, 706


```

Good news!  I have data for most of the rows for most of the variables that I planned to evaluate.  I will have to be careful when looking at the questions about exercise (PAQ655 and PAQ706) because of their low response rates.  Bummer!  I wanted to have a measure of daily exercise in the model, but I think I will plan on leaving those questions out for now.  I do still have PAQ710 and PAQ715 which ask about sedentary behavior which is something.


# Clearing up some more of the NA problems

I want to be strategic about how/whether I remove more of the NA values.  I am going to ignore PAQ655 and PAQ706 for now (and possibly I will ignore them completely).  It looks like other than those two, the largest number of NAs appears in MCQ300c.  MCQ300c has 1251 NAs but still has 5392 observations.  5392 seems like a respectable number of data points to me.  If remove all the rows where MCQ300c is NA, will that also remove all of the NAs from the other variables (except my exercise variables)?


```{r}

a1 <- nhn_GH_noNA %>% filter(!is.na(MCQ300C))

a1_obsCount <- apply(is.na(a1), 2, sum)
a1_obsCount
str(a1)

```

Bummer again!  I still have over 200 NAs in the income variable. I imagine that there is bias associated with removing observations from people who did not respond to the income data question--I suspect that the non-responders are not random; I imagine that non-responders are more likely to fall into one of the lower income categories (though would someone also be less likely to respond if they were in the top monthly income bracket?).  At any rate there are only 200 NAs that I am considering removing (out of the current 5392 observations), so I don't think removing these 200 observations will introduce significant bias. Let's see what happens if I remove those rows.  Will I be able to live with it or will I want to go back and leave some NAs in MCQ300?  


```{r}

b2 <- a1 %>% filter(!is.na(IND235))

b2_obsCount <- apply(is.na(b2), 2, sum)
b2_obsCount

```

Rrrgh!  Still almost 70 in some of the labs.   How many rows will I have left if I remove those NAs as well? 

```{r}

c3 <- b2 %>% filter(!is.na(LBXSCH))

c3_NaCount <- apply(is.na(c3), 2, sum)
c3_NaCount
nrow(c3)

c3_obsCount2 <- apply(!is.na(c3), 2, sum)
c3_obsCount2


#Note from Susannah.  When I did created this project this weekend (with the original data set); at this point the only columns that still had NAs in them were exercise columns that I had decided not to use.  Now with the updated data, I am getting 422 NAs in the BPXSY1.  I'm not sure where the problem happened along the data chain, but I am going to leave this code as is and not update the text.

#Additional even later note:  Having left the NAs in my model created problems for the predict function.  I talked with Luke and he says that having ~2000 observations is plenty, and I have more than twice that, so I have more than enough observations to remove the rest of the observations that still have NAs. (except PAQ655 and PAQ706 which I will abadon shortly--keep reading). 


z4 <- c3 %>% filter(!is.na(BPXSY1))
y5 <- z4 %>% filter(!is.na(DIQ172))
x6 <- y5 %>% filter(!is.na(BMXBMI))

x6_NaCount <- apply(is.na(x6), 2, sum)
x6_NaCount
nrow(x6)


```

I still have over 4000 (corrected see above-it was over 5000) observations which seems pretty good to me, but I did lose just under 20% of the observations by removing MCQ300c.  Tough decision. Do I keep these out or put them back in? Time to think a bit harder about what these variables really mean.  MCQ300c asks whether the respondent has a family history of diabetes.  I suspect this will be a strong predictor of the respondent's A1c level.  Is there something about the people who did not provide this family history information that is different than those who did provide the information?  Will removing these observations introduce additional bias to my model?  I cannot think of a reason that the MCQ300c non-responders would be substantially different than the other participants, so I am going to remove those rows.

```{r}
# Just renaming, so that the data frame name will remind me what it is
nhn_DM_noNA <- x6
str(nhn_DM_noNA)
```


# Finding and removing outliers

In reviewing the data (see above), I noticed an outlier in LBXSCH (the 639) and I also noticed that for some of the variables that I think should be binomial (like BPQ020 have you been told you have hypertension) yes vs no; I actually also have 9=don't know.  For my purposes, "don't know" is the same as NA.
I think I had better take an even closer look at my selected variables and remove any obvious outliers.  


```{r}

unique(nhn_DM_noNA$MCQ080)
unique(nhn_DM_noNA$SLQ050)
unique(nhn_DM_noNA$SLQ060)
unique(nhn_DM_noNA$BPQ020)
d4 <- nhn_DM_noNA %>% filter(LBXSCH != 639)
nrow(d4)

max(nhn_DM_noNA$LBXSGTSI)

# what is this error and how do I avoid it?:  Warning: longer object length is not a multiple of shorter object lengthWarning: longer object length is not a multiple of shorter object length.

nhn_DM_noNA_filtered <- d4 %>% filter(LBXSATSI < 250) %>% filter(LBXSCH < 300) %>% filter(MCQ080 != 9) %>% filter(MCQ300C != 9) %>% filter(MCQ365A != 9) %>% filter(BPQ020 != 9) %>%  filter(SLQ060 != 9) %>% filter(PAQ710 != 99)
nrow(nhn_DM_noNA_filtered)

max(nhn_DM_noNA_filtered$LBXSATSI)
max(nhn_DM_noNA_filtered$LBXSCH)

unique(nhn_DM_noNA_filtered$RIAGENDR)
unique(nhn_DM_noNA_filtered$MCQ080)
unique(nhn_DM_noNA_filtered$MCQ300C)
unique(nhn_DM_noNA_filtered$PAQ710)
unique(nhn_DM_noNA_filtered$PAQ715)
unique(nhn_DM_noNA_filtered$SLQ050)
unique(nhn_DM_noNA_filtered$SLQ060)
unique(nhn_DM_noNA_filtered$BPQ020)
unique(nhn_DM_noNA_filtered$MCQ365A)
unique(nhn_DM_noNA_filtered$SMQ020)
unique(nhn_DM_noNA_filtered$DIQ172)

nrow(nhn_DM_noNA_filtered)
nhn_DM_noNA_filtered <- nhn_DM_noNA_filtered %>% filter(LBXSGTSI < 300)
nhn_DM_noNA_filtered <- nhn_DM_noNA_filtered %>% filter(SMQ020 != 9) %>% filter(DIQ172 != 9)
nrow(nhn_DM_noNA_filtered)

# nhn_DM_noNA_filtered <- nhn_DM_noNA_filtered %>% filter(SMQ020 != 9) %>% filter(DIQ172 != 9)
# nrow(nhn_DM_noNA_filtered)

unique(nhn_DM_noNA_filtered$SMQ020)
unique(nhn_DM_noNA_filtered$DIQ172)

# I lost too many additional rows removing the 9s and from DIQ172 and SMQ020 (almost 1000 more rows)--I'm just leaving those in--I won't use these variables in most of the models in this project anyway (added later--so I went back and removed the rows with "9-don't know" in them-once I knew 3800 would be an adequate sample size).


# LBXGH   LBXSUA LBXSGTSI LBXSATSI   LBXSCH RIDAGEYR   IND235   MCQ080  MCQ300C   PAQ710   PAQ715   PAQ655   PAQ706  SLQ050   SLQ060   BPQ020   BPXSY1  MCQ365A 
  #Add RIAGENDR, DIQ172, SMQ020

```

Removing MCQ300c = 9 (don't know) removed almost 100 more rows, but since this is for my purposes the same as having a value of NA, and I already decided to remove the rows with NA in this category, I feel that removing the "don't know" response is reasonable.  Same thought process for the other "9-don't know" observation rows that I removed.  The rest of the outliers were single digit (or even single outlier), so I still have almost 5000 (now down to almost 4000) observations to work with.  I looked at all of the variables; any variable that I did not filter above, did not appear to have outliers. 
I noticed later in this project that I had GGTs in the 1500 range--not a lot, but they were making it hard to read my plots.  Normal range for GGT is 5 to 40; to have a GGT level in this range, it is either a typo or an incredibly exceptional event--I haven't even seen tylenol overdoses with complete liver failure in this range (300-400 is considered severely elevated); so I added a filter for GGT as above.


# Making my categorical variables into factors.

For PAQ710 and PAQ715 0-5 indicate increasing numbers of hours; then 8 means don't watch TV/use computer at all.  I actually talked with Kaitlyn about this, and we decided that even though this is an unusual dispersement of values, the different numbers do reflect real time values, so I will just leave these in not as factors and see if the model can detect that 8 means no TV/computer.  If this were a larger project, I would create the model both ways and see which model had better metrics.  Similar logic was used to not make the income variable into a factor.

```{r}


# This was changed later as above.
# nhn_DM_noNA_filtered$SMQ020 <- factor(nhn_DM_noNA_filtered$SMQ020)
# nhn_DM_noNA_filtered$DIQ172 <- factor(nhn_DM_noNA_filtered$DIQ172)


```




# Log of HgbA1c

As discussed above, I need to do a log transformation of my dependent variable LBXGH (Hemoglobin A1c).  From now-on, I will need to remember that any Coefficients I get from the model will be referring to the log of A1c rather than to A1c level itself.  I could also just convert the log_A1c back to A1c values.

```{r}

nhn_DM_noNA_filtered_log <- nhn_DM_noNA_filtered %>% mutate(LogA1c=log(LBXGH))
head(nhn_DM_noNA_filtered_log)

```



My dataframe name has gotten way too long.  I'll change it to something easier to understand/work with.

```{r}

LogA1c_rf_df <- nhn_DM_noNA_filtered_log

```

Side note:  I suspect capital letters in names are to be avoided for ease of typing, but I cannot imagine thinking of A1c without a capital A and once I have a capital A, I might as well get the capital L that I want for the word log.




# Looking at pairs of plots for evidence of linearity.

I tried looking at the pairs for all of the variables that I am still considering, but I got an error message about "finite 'ylim'" which an article from ProgrammingR (https://www.programmingr.com/r-error-messages/fixing-r-error-message-error-in-plot-window-need-finite-ylim-values/) said was related to having a column of NAs.  I removed the PAQ655 and PAQ706 that I have been wishful thinking keeping in my data frame and my pairs plots worked just fine:

```{r}

nhn_DM_for_pairs <- LogA1c_rf_df %>% dplyr::select(-PAQ655, -PAQ706)
head(nhn_DM_for_pairs)
pairs(nhn_DM_for_pairs)
unique(nhn_DM_for_pairs$MCQ080)
unique(nhn_DM_for_pairs$MCQ365A)

#Looking closer at my non-binomial/catergorical variables:
nhn_DM_for_pairs_nonbinom <- nhn_DM_for_pairs %>% dplyr::select(LogA1c, LBXGH, LBXSUA, LBXSGTSI, LBXSATSI, LBXSCH, RIDAGEYR, BPXSY1, BMXBMI)
pairs(nhn_DM_for_pairs_nonbinom)

```




# Creating Training and Testing Data Sets

```{r}


set.seed(715)
train_indices <- createDataPartition(y = LogA1c_rf_df$LogA1c, p = 0.8, list = FALSE)
train_DM <- LogA1c_rf_df[train_indices, ]
test_DM <- LogA1c_rf_df[-train_indices, ]
nrow(train_DM)
nrow(test_DM)

```

3118 observations in my training data and 778 observations in my test data.  TA felt this would be enough data for my model (as above).


# Regression Modeling

I chose multiple linear regression because my dependent variable is a continuous numerical variable, and I want to model the relationship between my dependent variable (HgbA1c level--actually log of A1c--see above) and multiple independent variables that I believe will be predictive. The assumptions for linear regression are:  Linearity--see pairs plots above; there may be linear relationships between the logA1c and some of my potential risk factor variables.  Independence--my understanding from reading through the NHANES supporting materials is that each observation comes from an independent separate person.  Normality of residuals (I will check).  And Equal Variances (I will check).

```{r}

#modified code from lecture 10 slides and class exercise

lm_DM1 = lm(LogA1c~LBXSUA+LBXSGTSI+LBXSATSI+LBXSCH+RIDAGEYR+IND235+MCQ080+MCQ300C+PAQ710+PAQ715+SLQ050+SLQ060+BPQ020+BPXSY1+MCQ365A, data = train_DM)
summary(lm_DM1)


```

I have some variables that have significant p-values (GGT, ALT, age, monthly income, relative with diabetes, computer use[variable chosen as a marker of sedentariness], trouble sleeping, hypertension, systolic blood pressure reading, and doctor told you to lose weight) and the p-value for the model itself is much less than 0.05, but the model itself has an adjusted R-squared of 0.1896 (down from 0.2318 before removing NAs), so this model only explains 19% of the variance. And the coefficients are very small, so the effect size for each variable in this current model is small.  Interestingly, based on the literature, I would have expected UA to be statistically significant which is not what I am seeing with my model.

p.s. I wrote the code for the model before I decided how to transform the A1c values.  I previously ran the model on LBXGH (not log) and my adjusted R2 was 0.1742, so it seems that making the log transformation did help.  Though 0.2318 is not as good as I would have hoped for, it is better than 0.1742.

pps No longer true.



Because UA was not statistically significant, as almost a side-note and to test my instincts, I'm going to run a model with UA alone.

```{r}

#modified code from lecture 10 slides and class exercise

lm_DM_UA = lm(LogA1c~LBXSUA, data = train_DM)
summary(lm_DM_UA)


```

Now the p-value for UA is extremely small (much less than 0.05)  BUT Multiple R-squared is very small at 0.0129, so only 1.3 % of the variance in LogA1c in this dataset is explained by UA.  The Coefficient is 0.008, so based on the observed beta, LogA1c increases by 0.008 mmol/mol for each 1 mg/dL increase in uric acid--which is almost a 1:1 increase when you transform the data back from LogA1c to A1c level.


# Residuals

Back to the first multiple variable model.  Let's plot the residuals to see if they are normal and have equal variances.  

```{r}

plot(fitted(lm_DM1), resid(lm_DM1))
hist(resid(lm_DM1))

```

My residuals could be better, but they could be worse as well.  The residuals do have a mean of zero and they are equal for the most part But actually there are more positive values than negative, so this isn't a perfect model in terms of equal variances.  The distribution of the residuals is now looking normal or very close to normal.  Again, not an ideal model, but also not terrible.




# Iterative Variable Selection

I admit that I started with too many variables.  All seem like variables that could be risk factors for high A1c, but even so this is still obviously an overly complex model.
As I clearly have a larger sample size than number of variables, I could use forward, backward, or both as my direction, but I chose to have use both directions to be able to weigh the effects as variables are added and also the effects of all variables simultaneously.  


```{r}

#modified from in-class lesson 10 exercise code


full_lm_DM1 = lm(LogA1c~LBXSUA+LBXSGTSI+LBXSATSI+LBXSCH+RIDAGEYR+IND235+MCQ080+MCQ300C+PAQ710+PAQ715+SLQ050+SLQ060+BPQ020+BPXSY1+MCQ365A, data = train_DM)
base__lm_DM1 = lm(LogA1c~1, data = train_DM)

DM1_stepAIC <- stepAIC(full_lm_DM1, scope = list(lower = base__lm_DM1, upper = full_lm_DM1), data = train_DM, direction = "both")

summary(DM1_stepAIC)


```

The adjusted Rsquared for my final model is about the same as the original model.  It has kept most of my original variables, but GGT, income, sedentary activity, one of the sleep questions and hypertension (but not elevated systolic BP) have been removed from the model.
AIC decreased from -15314 to -15323.



# Model 2

I'm going to try making a new model with only the 12 variables from the iterative method above.  And then see if the residuals are the same as for the original model.

```{r}

#modified code from lecture 10 slides and class exercise

lm_DM2 = lm(formula = LogA1c ~ LBXSUA + LBXSATSI + LBXSCH + RIDAGEYR + MCQ080 + MCQ300C + SLQ050 + BPXSY1 + MCQ365A, data = train_DM)
summary(lm_DM2)

plot(fitted(lm_DM2), resid(lm_DM2))
hist(resid(lm_DM2))

# LBXGH   LBXSUA LBXSGTSI LBXSATSI   LBXSCH RIDAGEYR   IND235   MCQ080  MCQ300C   PAQ710   PAQ715   PAQ655   PAQ706  SLQ050   SLQ060   BPQ020   BPXSY1  MCQ365A 

```

Not better in terms of Rsquared.  But it is interesting that that UA keeps coming back as not statistically signficant or should I say p-value = 0.143.  Reminder: I'm pretty sure I have seen literature on the association between UA and A1c.


Same model, but I removed UA again to see what the model performance would look like without it:

```{r}

#modified code from lecture 10 slides and class exercise

lm_DM2b = lm(formula = LogA1c ~ LBXSATSI + LBXSCH + RIDAGEYR + MCQ080 + MCQ300C + SLQ050 + BPXSY1 + MCQ365A, data = train_DM)
summary(lm_DM2b)

plot(fitted(lm_DM2b), resid(lm_DM2b))
hist(resid(lm_DM2b))

# LBXGH   LBXSUA LBXSGTSI LBXSATSI   LBXSCH RIDAGEYR   IND235   MCQ080  MCQ300C   PAQ710   PAQ715   PAQ655   PAQ706  SLQ050   SLQ060   BPQ020   BPXSY1  MCQ365A 

```
No real difference.  Maybe I should have known this change would not affect the model.



# Model 3a

I had a theory that MCQ080 and MCQ365a might be collinear because they both ask about being overweight.  MCQ080 is more specific, but I wonder how predictive each variable would be on its own.  


```{r}

#checking to see if their values appear to be collinear
table(train_DM$MCQ080, train_DM$MCQ365A)

#modified code from lecture 10 slides and class exercise

lm_DM_MCQ080 = lm(LogA1c~MCQ080, data = train_DM)
summary(lm_DM_MCQ080)
lm_DM_MCQ365A = lm(LogA1c~MCQ365A, data = train_DM)
summary(lm_DM_MCQ365A)

# LBXGH   LBXSUA LBXSGTSI LBXSATSI   LBXSCH RIDAGEYR   IND235   MCQ080  MCQ300C   PAQ710   PAQ715   PAQ655   PAQ706  SLQ050   SLQ060   BPQ020   BPXSY1  MCQ365A 

```

Both have significant p-values (extremely small).  Adjusted Rsquare values are similar at 0.0202 for MCQ080 and 0.01657 for MCQ365A.  As another side note:  I had much better Rsquared values for all of my models before I removed the extra 1000 observations to remove the rest of the NAs from my model.  Either there is something about the particular observations that I removed (did I unwittingly introduce bias) or this speaks of the power of large sample sizes.  I hope the predict function works now to justify the data loss and worse model metrics.



# Model 3b

BPQ020 and BPXSYS1 both evaluate the person's blood pressure.  BPQ020 asks if a person has a diagnosis of hypertension (high blood pressure); BPXSYS1 tells me what a person's blood pressure currently is.  From the literature, it is known that high blood pressure is a risk factor for diabetes, but I'm not sure which measure I think would be more relevant.  A person could be anxious, in pain, or have some other reason for having a 1-time elevated blood pressure at the time of the nhanes evaluation without having a high blood pressure condition; in this case the elevated blood pressure would be less likely to be predictive of diabetes.  On the other hand, a person with a known diagnosis of hypertension (elevated blood pressure) may take medications that keep their blood pressure consistently well-controlled whereas others with hypertension may not control their blood pressure well.  The uncontrolled hypertensives would be more likely to be predictive of diabetes (which I would need to use BPXSYS to look at--in this case, the actual blood pressure reading at the time of the nhanes evaluation would be the more predictive variable.  Also of note, I opted to use only BPXSYS1 in my model because I am looking for highest BP readings.  The follow-up readings in BPXSYS2-4 seem to be readings from as the patient is given time, and their BP comes down.  I also did not average the BP readings because again what I am interested in is: is elevated BP predictive of A1c reading.  Let's see what modeling says: 


```{r}

#modified code from lecture 10 slides and class exercise

lm_DM_BPQ020 = lm(LogA1c~BPQ020, data = train_DM)
summary(lm_DM_BPQ020)
lm_DM_BPXSY1 = lm(LogA1c~BPXSY1, data = train_DM)
summary(lm_DM_BPXSY1)


```


Again both have signficant p-values. In single variable linear regression with this data set, the first blood pressure reading recorded explains more of the variance in my A1c data (LogA1c data) that the diagnosis of hypertension (6.0% vs 3.7%).



# This just in:  New data from Luke!!!

We just got more nhanes variables to work with (as noted above, but this is where I was in the project when I saw the update from Luke).  There is a lot of diabetes survey data, but the one that I am most interested in for a risk factor prediction model is "do you feel you are at risk for diabetes?"  Arguably, this is not a useful question as those with high A1c levels are likely to no longer "feel they are at risk for diabetes" and they may now know they have diabetes.  But I suspect those who have diabetes would respond yes to this question (as responding no I do not feel that I am at risk for diabetes when I already know I have diabetes is even less logical).  So let's see what happens.  Also smoking and BMI are likely risk factors for diabetes-or more specifically for elevated A1c/uncontrolled diabetes. I went back and added these three variables to my original data frame and did the data processing for these.  I brought in gender as well although I am not aware of a specific gender relationship with elevated A1c level.  Let's see what a linear regression model with just these four variables would look like.

```{r}

#modified code from lecture 10 slides and class exercise

lm_DM_new_data = lm(LogA1c~BMXBMI + RIAGENDR + DIQ172 + SMQ020, data = train_DM)
summary(lm_DM_new_data)



```

The adjusted R-squared is lower than what I had been seeing for my previous models at 0.05717.  p-values are all below 0.05, so all chosen variables do appear to be predictive of LogA1c value.  To be clear, it looks like the "2-No" for smoking is negatively predictive which I interpret to mean LogA1c decreases with NOT smoking.   


# Re-conducting Iterative Variable Selection

I'm going to try iterative variable selection one more time-now with the 4 additional variables in hopes that it will help me find my very best model.

```{r}

#modified from in-class lesson 10 exercise code

full_lm_DM_new = lm(LogA1c~LBXSUA+LBXSGTSI+LBXSATSI+LBXSCH+RIDAGEYR+IND235+MCQ080+MCQ300C+PAQ710+PAQ715+SLQ050+SLQ060+BPQ020+BPXSY1+MCQ365A + BMXBMI + RIAGENDR + DIQ172 + SMQ020, data = train_DM)
base_lm_DM_new = lm(LogA1c~1, data = train_DM)

StepAIC_DM_new <- stepAIC(full_lm_DM_new, scope = list(lower = base_lm_DM_new, upper = full_lm_DM_new), data = train_DM, direction = "both")

summary(StepAIC_DM_new)

```

We are now down to 9 variables, and we have brought the adjusted Rsquared back up to the 22% range--now 0.2189.  But now the subset of variables that result in the best performing model are much different than what was chosen for my first model-I have 6 variables from the first model (LBXSATSI, LBXSCH, RIDAGEYR, MCQ300C, SLQ050, and BPXSY1) along with BMXBMI, RIAGENDR and DIQ172 from the new variables. UA was recommended in the first Stepwise AIC but not in this one.  Poor UA-it's not significant, it's recommended, still not significant, now it's no longer recommended; how must you feel little UA?

Over the course of this iteritive process AIC decreased from -15419 to AIC=-15435.



# Plotting the residuals one last time


```{r}

final_lm <- lm(formula = LogA1c ~ LBXSATSI + LBXSCH + RIDAGEYR + MCQ300C + SLQ050 + BPXSY1 + BMXBMI + RIAGENDR + DIQ172, data = train_DM)
summary(final_lm)
plot(fitted(final_lm), resid(final_lm))
hist(resid(final_lm))

```

Still not equal variances and still not normally distributed.  I will need to note this in the discussion.  



# Prediction!

I have now created a predictive model.  Let's see how good it is at its job of predicting:

```{r}
###Office Hours!!!

LogA1c_predictions <- predict(final_lm, newdata = test_DM)
rmse(LogA1c_predictions, test_DM$LogA1c)
```

Lower rmse scores are better.  One would hope for a value between 0.2 and 0.5.  Clearly, this model is not performing well; but this was to be expected given the Rsquared values that we were seeing.  



# Blue text

Black text
Black text


```{r}

```

Black text
Black text
